Python 3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)] on win32
Type "help", "copyright", "credits" or "license" for more information.
>>> import os
>>> os.chdir ('C:\\projects\\digits_bot\\NeuralNetwork\\Network2')
>>> import mnist_loader
>>> training_data, validation_data, test_data = mnist_loader.load_data_wrapper()
>>> import network2
>>> net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)
>>> net.SGD(training_data, 30, 10, 0.5, lmbda = 5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True, monitor_evaluation_cost=True, monitor_training_accuracy=True, monitor_training_cost=True)
Epoch 0 training complete
--Cost on training data: 0.471647656522799
--Accuracy on training data: 47109 / 50000
--Cost on evaluation data: 0.7820802119638912
--Accuracy on evaluation data: 9427 / 10000
Epoch 1 training complete
--Cost on training data: 0.42703314957512917
--Accuracy on training data: 47635 / 50000
--Cost on evaluation data: 0.84022043113667
--Accuracy on evaluation data: 9496 / 10000
Epoch 2 training complete
--Cost on training data: 0.4264707541881114
--Accuracy on training data: 47732 / 50000
--Cost on evaluation data: 0.8924353731394861
--Accuracy on evaluation data: 9526 / 10000
Epoch 3 training complete
--Cost on training data: 0.4097818934932993
--Accuracy on training data: 48030 / 50000
--Cost on evaluation data: 0.9058172411137905
--Accuracy on evaluation data: 9562 / 10000
Epoch 4 training complete
--Cost on training data: 0.38848380484771067
--Accuracy on training data: 48107 / 50000
--Cost on evaluation data: 0.9042527808363041
--Accuracy on evaluation data: 9563 / 10000
Epoch 5 training complete
--Cost on training data: 0.39882721004109145
--Accuracy on training data: 48108 / 50000
--Cost on evaluation data: 0.932251500957288
--Accuracy on evaluation data: 9544 / 10000
Epoch 6 training complete
--Cost on training data: 0.39021792899258395
--Accuracy on training data: 48182 / 50000
--Cost on evaluation data: 0.9337128295869681
--Accuracy on evaluation data: 9595 / 10000
Epoch 7 training complete
--Cost on training data: 0.3903596463689101
--Accuracy on training data: 48214 / 50000
--Cost on evaluation data: 0.9398762956328852
--Accuracy on evaluation data: 9577 / 10000
Epoch 8 training complete
--Cost on training data: 0.3841397502044408
--Accuracy on training data: 48316 / 50000
--Cost on evaluation data: 0.9409982678897995
--Accuracy on evaluation data: 9592 / 10000
Epoch 9 training complete
--Cost on training data: 0.39163256447855954
--Accuracy on training data: 48157 / 50000
--Cost on evaluation data: 0.9419095955612828
--Accuracy on evaluation data: 9601 / 10000
Epoch 10 training complete
--Cost on training data: 0.3961409062780109
--Accuracy on training data: 48260 / 50000
--Cost on evaluation data: 0.9563359807217007
--Accuracy on evaluation data: 9599 / 10000
Epoch 11 training complete
--Cost on training data: 0.42307660029818095
--Accuracy on training data: 47964 / 50000
--Cost on evaluation data: 0.9892689782488984
--Accuracy on evaluation data: 9542 / 10000
Epoch 12 training complete
--Cost on training data: 0.38282196394810775
--Accuracy on training data: 48300 / 50000
--Cost on evaluation data: 0.9462162176816662
--Accuracy on evaluation data: 9609 / 10000
Epoch 13 training complete
--Cost on training data: 0.38435197404540655
--Accuracy on training data: 48357 / 50000
--Cost on evaluation data: 0.9617548129461322
--Accuracy on evaluation data: 9594 / 10000
Epoch 14 training complete
--Cost on training data: 0.36974000579164823
--Accuracy on training data: 48414 / 50000
--Cost on evaluation data: 0.9496503447906837
--Accuracy on evaluation data: 9606 / 10000
Epoch 15 training complete
--Cost on training data: 0.39202897352377414
--Accuracy on training data: 48243 / 50000
--Cost on evaluation data: 0.9667449992267344
--Accuracy on evaluation data: 9594 / 10000
Epoch 16 training complete
--Cost on training data: 0.38374517400849983
--Accuracy on training data: 48370 / 50000
--Cost on evaluation data: 0.9590212337132826
--Accuracy on evaluation data: 9604 / 10000
Epoch 17 training complete
--Cost on training data: 0.3884954008335022
--Accuracy on training data: 48262 / 50000
--Cost on evaluation data: 0.97424786348615
--Accuracy on evaluation data: 9552 / 10000
Epoch 18 training complete
--Cost on training data: 0.37182791332602
--Accuracy on training data: 48486 / 50000
--Cost on evaluation data: 0.947205651389562
--Accuracy on evaluation data: 9633 / 10000
Epoch 19 training complete
--Cost on training data: 0.3619974214031162
--Accuracy on training data: 48461 / 50000
--Cost on evaluation data: 0.9466427529983761
--Accuracy on evaluation data: 9622 / 10000
Epoch 20 training complete
--Cost on training data: 0.4144084442260579
--Accuracy on training data: 48201 / 50000
--Cost on evaluation data: 0.9805789430207863
--Accuracy on evaluation data: 9585 / 10000
Epoch 21 training complete
--Cost on training data: 0.377274549636241
--Accuracy on training data: 48387 / 50000
--Cost on evaluation data: 0.9528917092213574
--Accuracy on evaluation data: 9609 / 10000
Epoch 22 training complete
--Cost on training data: 0.3658120239799161
--Accuracy on training data: 48529 / 50000
--Cost on evaluation data: 0.9480002205138164
--Accuracy on evaluation data: 9608 / 10000
Epoch 23 training complete
--Cost on training data: 0.36734389309353993
--Accuracy on training data: 48416 / 50000
--Cost on evaluation data: 0.9523566887247172
--Accuracy on evaluation data: 9614 / 10000
Epoch 24 training complete
--Cost on training data: 0.4155318325456373
--Accuracy on training data: 48019 / 50000
--Cost on evaluation data: 1.0009587367973993
--Accuracy on evaluation data: 9540 / 10000
Epoch 25 training complete
--Cost on training data: 0.3693493105082353
--Accuracy on training data: 48436 / 50000
--Cost on evaluation data: 0.9491356503851074
--Accuracy on evaluation data: 9616 / 10000
Epoch 26 training complete
--Cost on training data: 0.37671255948015747
--Accuracy on training data: 48383 / 50000
--Cost on evaluation data: 0.9585900354432237
--Accuracy on evaluation data: 9600 / 10000
Epoch 27 training complete
--Cost on training data: 0.37190416437240753
--Accuracy on training data: 48342 / 50000
--Cost on evaluation data: 0.95394536963553
--Accuracy on evaluation data: 9608 / 10000
Epoch 28 training complete
--Cost on training data: 0.42244956396803074
--Accuracy on training data: 48012 / 50000
--Cost on evaluation data: 0.990406944695164
--Accuracy on evaluation data: 9543 / 10000
Epoch 29 training complete
--Cost on training data: 0.37607683957880034
--Accuracy on training data: 48419 / 50000
--Cost on evaluation data: 0.9579302926783713
--Accuracy on evaluation data: 9611 / 10000
([0.7820802119638912, 0.84022043113667, 0.8924353731394861, 0.9058172411137905, 0.9042527808363041, 0.932251500957288, 0.9337128295869681, 0.9398762956328852, 0.9409982678897995, 0.9419095955612828, 0.9563359807217007, 0.9892689782488984, 0.9462162176816662, 0.9617548129461322, 0.9496503447906837, 0.9667449992267344, 0.9590212337132826, 0.97424786348615, 0.947205651389562, 0.9466427529983761, 0.9805789430207863, 0.9528917092213574, 0.9480002205138164, 0.9523566887247172, 1.0009587367973993, 0.9491356503851074, 0.9585900354432237, 0.95394536963553, 0.990406944695164, 0.9579302926783713], [9427, 9496, 9526, 9562, 9563, 9544, 9595, 9577, 9592, 9601, 9599, 9542, 9609, 9594, 9606, 9594, 9604, 9552, 9633, 9622, 9585, 9609, 9608, 9614, 9540, 9616, 9600, 9608, 9543, 9611], [0.471647656522799, 0.42703314957512917, 0.4264707541881114, 0.4097818934932993, 0.38848380484771067, 0.39882721004109145, 0.39021792899258395, 0.3903596463689101, 0.3841397502044408, 0.39163256447855954, 0.3961409062780109, 0.42307660029818095, 0.38282196394810775, 0.38435197404540655, 0.36974000579164823, 0.39202897352377414, 0.38374517400849983, 0.3884954008335022, 0.37182791332602, 0.3619974214031162, 0.4144084442260579, 0.377274549636241, 0.3658120239799161, 0.36734389309353993, 0.4155318325456373, 0.3693493105082353, 0.37671255948015747, 0.37190416437240753, 0.42244956396803074, 0.37607683957880034], [47109, 47635, 47732, 48030, 48107, 48108, 48182, 48214, 48316, 48157, 48260, 47964, 48300, 48357, 48414, 48243, 48370, 48262, 48486, 48461, 48201, 48387, 48529, 48416, 48019, 48436, 48383, 48342, 48012, 48419])
>>>